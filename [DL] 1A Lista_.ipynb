{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os padrões de entrada (vértices do cubo)\n",
    "entradas = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1]\n",
    "]).astype(float)\n",
    "\n",
    "# Vetores de resposta associados a cada padrão de entrada\n",
    "respostas = np.array([\n",
    "    [1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [-1, 1, -1, -1, -1, -1, -1, -1],\n",
    "    [-1, -1, 1, -1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, 1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, 1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1, 1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1, -1, 1, -1],\n",
    "    [-1, -1, -1, -1, -1, -1, -1, 1]\n",
    "]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Função para adicionar ruído aos padrões de entrada\n",
    "def adicionar_ruido(entradas, raio_ruido):\n",
    "    # Cria uma cópia das entradas para não alterar o array original\n",
    "    entradas_ruidosas = np.copy(entradas)\n",
    "    # Adiciona ruído aleatório dentro do raio especificado\n",
    "    ruido = np.random.uniform(-raio_ruido, raio_ruido, entradas.shape)\n",
    "    entradas_ruidosas += ruido\n",
    "    return entradas_ruidosas\n",
    "\n",
    "# Definindo o raio máximo do ruído\n",
    "raio_ruido = 0.1\n",
    "\n",
    "# Criando o conjunto de validação com ruído\n",
    "conjunto_validacao = adicionar_ruido(entradas, raio_ruido)\n",
    "conjunto_validacao.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X: (3, 8)\n",
      "The shape of Y: (8, 8)\n",
      "I have m = 8 training examples!\n"
     ]
    }
   ],
   "source": [
    "X = entradas.T\n",
    "Y = respostas.reshape((8, len(respostas)))\n",
    "\n",
    "print ('The shape of X: ' + str(X.shape))\n",
    "print ('The shape of Y: ' + str(Y.shape))\n",
    "print ('I have m = %d training examples!' % (X.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron de Rosenblatt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y):\n",
    "    n_x = X.shape[0]  # Size of input layer\n",
    "    n_y = Y.shape[0]  # Size of output layer\n",
    "    return (n_x, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the input layer is: n_x = 3\n",
      "The size of the output layer is: n_y = 8\n"
     ]
    }
   ],
   "source": [
    "(n_x, n_y) = layer_sizes(X, Y)\n",
    "print(\"The size of the input layer is: n_x = \" + str(n_x))\n",
    "print(\"The size of the output layer is: n_y = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 8 exemplos de treinamento, com 3 atributos cada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_y):\n",
    "    W = np.random.randn(n_y, n_x) * 0.01  # Small random weights\n",
    "    b = np.zeros((n_y, 1))  # Bias initialized to zero\n",
    "    return {\"W\": W, \"b\": b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W = parameters['W']\n",
    "    b = parameters['b']\n",
    "    Z = np.dot(W, X) + b\n",
    "    A = np.where(Z > 0, 1, -1)  # Activation using sign function\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, X, Y, learning_rate):\n",
    "    m = X.shape[1]  # Número de exemplos de treinamento\n",
    "    W = parameters['W']\n",
    "    b = parameters['b']\n",
    "    for i in range(m):  # Iterar sobre cada exemplo de treinamento\n",
    "        xi = X[:, [i]]  # Pegar a coluna i de X\n",
    "        yi = Y[:, [i]]  # Pegar a coluna i de Y\n",
    "        A = forward_propagation(xi, parameters)  # Previsão para o exemplo xi\n",
    "        for j in range(Y.shape[0]):  # Iterar sobre cada saída\n",
    "            if yi[j, 0] != A[j, 0]:  # Se a previsão estiver incorreta\n",
    "                # Atualizar W e b para cada saída j\n",
    "                W[j, :] = W[j, :] + learning_rate * yi[j, 0] * xi.T\n",
    "                b[j, 0] = b[j, 0] + learning_rate * yi[j, 0]\n",
    "    parameters['W'] = W\n",
    "    parameters['b'] = b\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def nn_model(X, Y, num_iterations=100, learning_rate=0.001):\n",
    "    n_x, n_y = layer_sizes(X, Y)\n",
    "    parameters = initialize_parameters(n_x, n_y)\n",
    "    for i in range(num_iterations):\n",
    "        parameters = update_parameters(parameters, X, Y, learning_rate)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "parameters = nn_model(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: [-0.00408358  0.0168399   0.0473645 ] | Saída Prevista: [ 1 -1 -1 -1 -1 -1 -1 -1] | Esperado: [ 1. -1. -1. -1. -1. -1. -1. -1.] | ✅ Acertou\n",
      "Entrada: [0.01154845 0.01730709 1.01289171] | Saída Prevista: [-1  1 -1 -1 -1 -1 -1 -1] | Esperado: [-1.  1. -1. -1. -1. -1. -1. -1.] | ✅ Acertou\n",
      "Entrada: [-0.02424547  0.96748937  0.07992948] | Saída Prevista: [-1 -1  1 -1 -1 -1 -1 -1] | Esperado: [-1. -1.  1. -1. -1. -1. -1. -1.] | ✅ Acertou\n",
      "Entrada: [0.02151104 0.94887063 0.99964954] | Saída Prevista: [-1 -1 -1  1 -1 -1 -1 -1] | Esperado: [-1. -1. -1.  1. -1. -1. -1. -1.] | ✅ Acertou\n",
      "Entrada: [ 0.9660697   0.08673836 -0.09849313] | Saída Prevista: [-1 -1 -1 -1  1 -1 -1 -1] | Esperado: [-1. -1. -1. -1.  1. -1. -1. -1.] | ✅ Acertou\n",
      "Entrada: [ 0.94506656 -0.02692864  0.99756196] | Saída Prevista: [-1 -1 -1 -1 -1  1 -1 -1] | Esperado: [-1. -1. -1. -1. -1.  1. -1. -1.] | ✅ Acertou\n",
      "Entrada: [1.0701635  0.91757752 0.06117298] | Saída Prevista: [-1 -1 -1 -1 -1 -1  1 -1] | Esperado: [-1. -1. -1. -1. -1. -1.  1. -1.] | ✅ Acertou\n",
      "Entrada: [0.9111307  1.06846281 0.9103271 ] | Saída Prevista: [-1 -1 -1 -1 -1 -1 -1  1] | Esperado: [-1. -1. -1. -1. -1. -1. -1.  1.] | ✅ Acertou\n"
     ]
    }
   ],
   "source": [
    "def predict(parameters, X):\n",
    "    W = parameters['W']\n",
    "    b = parameters['b']\n",
    "    Z = np.dot(W, X) + b\n",
    "    A = np.where(Z > 0, 1, -1)  # Aplica a função sinal\n",
    "    \n",
    "    predictions = A\n",
    "    return predictions\n",
    "\n",
    "# Realizando previsões com o modelo treinado\n",
    "predictions = predict(parameters,conjunto_validacao.T)\n",
    "\n",
    "# Agora, faça a iteração e imprima os resultados\n",
    "for i in range(len(predictions)):\n",
    "    # Assegure-se de que estamos comparando valores escalares\n",
    "    acertou = \"✅ Acertou\" if np.array_equal(predictions[i], respostas[i])  else \"❌ Errou\"\n",
    "    print(f\"Entrada: {conjunto_validacao[i]} | Saída Prevista: {predictions[i]} | Esperado: {respostas[i]} | {acertou}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [1, 1],\n",
       "        [0, 1],\n",
       "        [0, 0]]),\n",
       " array([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "        1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "        1, 0, 1, 0]),\n",
       " array([[1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 0],\n",
       "        [0, 1],\n",
       "        [1, 0],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [0, 1]]),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1, 0, 1]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo a função lógica XOR\n",
    "def xor_function(x1, x2):\n",
    "    return np.where(x1 == x2, 0, 1)\n",
    "\n",
    "# Gerando um conjunto de amostras para a função XOR\n",
    "np.random.seed(42)  # Para resultados reprodutíveis\n",
    "x1_samples = np.random.randint(0, 2, 100)  # Gerando 100 amostras para x1\n",
    "x2_samples = np.random.randint(0, 2, 100)  # Gerando 100 amostras para x2\n",
    "y_samples = xor_function(x1_samples, x2_samples)  # Calculando os rótulos com a função XOR\n",
    "\n",
    "# Dividindo as amostras em conjuntos de treinamento (70%) e validação (30%)\n",
    "indices = np.random.permutation(len(x1_samples))\n",
    "train_indices = indices[:70]\n",
    "val_indices = indices[70:]\n",
    "\n",
    "x_train = np.array([x1_samples[train_indices], x2_samples[train_indices]]).T\n",
    "y_train = y_samples[train_indices]\n",
    "x_val = np.array([x1_samples[val_indices], x2_samples[val_indices]]).T\n",
    "y_val = y_samples[val_indices]\n",
    "\n",
    "# Verificando as amostras de treinamento e validação\n",
    "x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "    \n",
    "        parameters['W' + str(l)] =  np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "  \n",
    "    Z = np.dot(W,A) + b\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2  # number of layers in the neural network\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        \n",
    "        # Camadas ocultas\n",
    "        A, cache = linear_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)])\n",
    "        caches.append(cache)\n",
    "\n",
    "    # Ultima camada \n",
    "    AL, cache = linear_forward(A, parameters['W' + str(L)], parameters['b' + str(L)])\n",
    "    caches.append(cache)\n",
    "          \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    cost = -np.sum(Y * np.log(AL) + (1 - Y) * np.log(1 - AL))/ m\n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X, Y, num_iterations=10, print_cost=False, learning_rate = 0.01):\n",
    "    \n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[1]\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_x,n_y)\n",
    "    \n",
    "    # Loop\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        # Forward propagation. Inputs: \"X, parameters, n_y\". Outputs: \"Y_hat\".\n",
    "        Y_hat = forward_propagation(X,parameters)\n",
    "        \n",
    "        # Cost function. Inputs: \"Y_hat, Y\". Outputs: \"cost\".\n",
    "        cost = compute_cost(Y_hat,Y)\n",
    "\n",
    "        # Parameters update:\n",
    "        # Backward propagation. Inputs: \"parameters, X, Y, Y_hat\". Outputs: \"grads\".\n",
    "        dW = (1/X.shape[1]) * np.dot((Y_hat - Y), X.T)\n",
    "        db = (1/X.shape[1]) * np.sum(Y_hat - Y, axis=1, keepdims=True)\n",
    "\n",
    "        # Update rule for each parameter.\n",
    "        parameters[\"W\"] = parameters[\"W\"] - learning_rate * dW\n",
    "        parameters[\"b\"] = parameters[\"b\"] - learning_rate * db\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "   \n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    \n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def update_parameters(params, grads, learning_rate):\n",
    "   \n",
    "    parameters = copy.deepcopy(params)\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "       \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W1_Assignment_Solution.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "AI4MC1-1"
   ]
  },
  "grader_version": "2",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
