{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os padrões de entrada (vértices do cubo)\n",
    "entradas = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1]\n",
    "]).astype(float)\n",
    "\n",
    "# Vetores de resposta associados a cada padrão de entrada\n",
    "respostas = np.array([\n",
    "    [1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    [-1, 1, -1, -1, -1, -1, -1, -1],\n",
    "    [-1, -1, 1, -1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, 1, -1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, 1, -1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1, 1, -1, -1],\n",
    "    [-1, -1, -1, -1, -1, -1, 1, -1],\n",
    "    [-1, -1, -1, -1, -1, -1, -1, 1]\n",
    "]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Função para adicionar ruído aos padrões de entrada\n",
    "def adicionar_ruido(entradas, raio_ruido):\n",
    "    # Cria uma cópia das entradas para não alterar o array original\n",
    "    entradas_ruidosas = np.copy(entradas)\n",
    "    # Adiciona ruído aleatório dentro do raio especificado\n",
    "    ruido = np.random.uniform(-raio_ruido, raio_ruido, entradas.shape)\n",
    "    entradas_ruidosas += ruido\n",
    "    return entradas_ruidosas\n",
    "\n",
    "# Definindo o raio máximo do ruído\n",
    "raio_ruido = 0.2\n",
    "\n",
    "# Criando o conjunto de validação com ruído\n",
    "conjunto_validacao = adicionar_ruido(entradas, raio_ruido)\n",
    "conjunto_validacao.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X: (3, 8)\n",
      "The shape of Y: (8, 8)\n",
      "I have m = 8 training examples!\n"
     ]
    }
   ],
   "source": [
    "X = entradas.T\n",
    "Y = respostas.reshape((8, len(respostas)))\n",
    "\n",
    "print ('The shape of X: ' + str(X.shape))\n",
    "print ('The shape of Y: ' + str(Y.shape))\n",
    "print ('I have m = %d training examples!' % (X.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron de Rosenblatt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y):\n",
    "    # Size of input layer.\n",
    "    n_x = X.shape[0]\n",
    "    # Size of output layer.\n",
    "    n_y = Y.shape[0]\n",
    "    \n",
    "    return (n_x, n_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the input layer is: n_x = 3\n",
      "The size of the output layer is: n_y = 8\n"
     ]
    }
   ],
   "source": [
    "(n_x, n_y) = layer_sizes(X, Y)\n",
    "print(\"The size of the input layer is: n_x = \" + str(n_x))\n",
    "print(\"The size of the output layer is: n_y = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 8 exemplos de treinamento, com 3 atributos cada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_y):\n",
    "\n",
    "    # matriz de pesos, inicializada com valores aleatórios e pequenos para evitar a saturação da função de ativação\n",
    "    W = np.random.randn(n_y,n_x) * 0.01\n",
    "    b = np.zeros((n_y,1))\n",
    "    \n",
    "    assert (W.shape == (n_y, n_x))\n",
    "    assert (b.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W\": W,\n",
    "                  \"b\": b}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "  \n",
    "    W = parameters['W']\n",
    "    b = parameters['b']\n",
    "   \n",
    "    \n",
    "    # Forward Propagation to calculate Z.\n",
    "    Z = np.dot(W,X) + b\n",
    "    Y_hat = Z\n",
    "    \n",
    "    #assert(Y_hat.shape == (n_y, X.shape[1]))\n",
    "\n",
    "    return Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_cost(Y_hat, Y):\n",
    "    \n",
    "    # Number of examples.\n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute the cost function.\n",
    "    cost = np.sum((Y_hat - Y)**2)/(2*m) # Mean Squared Error\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def nn_model(X, Y, num_iterations=10, print_cost=False, learning_rate = 0.01):\n",
    "    \n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[1]\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_x,n_y)\n",
    "    \n",
    "    # Loop\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        # Forward propagation. Inputs: \"X, parameters, n_y\". Outputs: \"Y_hat\".\n",
    "        Y_hat = forward_propagation(X,parameters)\n",
    "        \n",
    "        # Cost function. Inputs: \"Y_hat, Y\". Outputs: \"cost\".\n",
    "        cost = compute_cost(Y_hat,Y)\n",
    "\n",
    "        # Parameters update:\n",
    "        # Backward propagation. Inputs: \"parameters, X, Y, Y_hat\". Outputs: \"grads\".\n",
    "        dW = (1/X.shape[1]) * np.dot((Y_hat - Y), X.T)\n",
    "        db = (1/X.shape[1]) * np.sum(Y_hat - Y, axis=1, keepdims=True)\n",
    "\n",
    "        # Update rule for each parameter.\n",
    "        parameters[\"W\"] = parameters[\"W\"] - learning_rate * dW\n",
    "        parameters[\"b\"] = parameters[\"b\"] - learning_rate * db\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 1.6484282182199619\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(X, Y, num_iterations=100, print_cost=True)\n",
    "print(\"cost = \" + str(compute_cost(forward_propagation(X, parameters), Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 2 3 4 5 6 7]\n",
      "Entrada:  [0.01829261 0.04093529 0.12759377] Saída:  0 [ 1. -1. -1. -1. -1. -1. -1. -1.]\n",
      "Entrada:  [-0.02180318 -0.00382869  1.08725824] Saída:  1 [-1.  1. -1. -1. -1. -1. -1. -1.]\n",
      "Entrada:  [-0.07664855  1.03143127  0.11862453] Saída:  2 [-1. -1.  1. -1. -1. -1. -1. -1.]\n",
      "Entrada:  [0.01099033 0.80024164 1.15350762] Saída:  3 [-1. -1. -1.  1. -1. -1. -1. -1.]\n",
      "Entrada:  [ 1.02595715  0.04904776 -0.03595533] Saída:  4 [-1. -1. -1. -1.  1. -1. -1. -1.]\n",
      "Entrada:  [ 0.83802669 -0.15251605  0.87007586] Saída:  5 [-1. -1. -1. -1. -1.  1. -1. -1.]\n",
      "Entrada:  [ 0.86415394  1.11091083 -0.02273131] Saída:  6 [-1. -1. -1. -1. -1. -1.  1. -1.]\n",
      "Entrada:  [0.83924986 1.16163806 0.90788903] Saída:  7 [-1. -1. -1. -1. -1. -1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Função predict para classificação multiclasse\n",
    "def predict(X, parameters):\n",
    "    Y_hat = forward_propagation(X, parameters)\n",
    "    Y_prediction = np.argmax(Y_hat, axis=0)\n",
    "\n",
    "    return Y_prediction\n",
    "\n",
    "# Realizando previsões com o modelo treinado\n",
    "predictions = predict(conjunto_validacao.T, parameters)\n",
    "print(\"Predictions:\", predictions)\n",
    "\n",
    "for i in range(8):\n",
    "    print(\"Entrada: \", conjunto_validacao[i], \"Saída: \", predictions[i] , respostas[predictions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "C1_W1_Assignment_Solution.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "AI4MC1-1"
   ]
  },
  "grader_version": "2",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
